import React, { useState, useRef, useEffect } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as poseDetection from '@tensorflow-models/pose-detection';
import { AMDF } from 'pitchfinder';

import { initLLM, generateMusicFeedback } from './aiEngine';

function App() {
	const [videoUrl, setVideoUrl] = useState(null);
	const [sheetUrl, setSheetUrl] = useState(null);
	const [isAnalyzing, setIsAnalyzing] = useState(false);

	const [analysisStep, setAnalysisStep] = useState('idle'); // idle, processing, generating, completed
	const [llmReady, setLlmReady] = useState(false);
	const [llmProgress, setLlmProgress] = useState(0);

	const [llmStatus, setLlmStatus] = useState("");

	const hasInitialized = useRef(false); // ìƒë‹¨ì— ì¶”ê°€

	// AI ì—”ì§„ ì˜ˆì—´ í™•ì¸
	useEffect(() => {
		if (hasInitialized.current) return; // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì°¨ë‹¨
		hasInitialized.current = true;

		const startLLM = async () => {
			try {
				await initLLM((p) => {
					const progress = Math.round(p.progress * 100);
					setLlmProgress(progress);

					if (progress >= 100) {
						setLlmReady(true);
						setLlmStatus("AI ì½”ì¹˜ ì¤€ë¹„ ì™„ë£Œ");
					} else {
						setLlmStatus(`AI ì—”ì§„ ë¡œë”© ì¤‘... (${progress}%)`);
					}
				});
			} catch (err) {
				console.error("ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨:", err);
				setLlmStatus("AI ì—”ì§„ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
				hasInitialized.current = false; // ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ê°€ëŠ¥í•˜ê²Œ
			}
		};

		startLLM();
	}, []);
	// useEffect(() => {
	// 	initLLM((p) => {
	// 		setLlmProgress(Math.round(p.progress * 100));
	// 		if (p.progress === 1) {
	// 			setLlmReady(true);
	// 			setLlmStatus("AI ì½”ì¹˜ ì¤€ë¹„ ì™„ë£Œ");
	// 		} else {
	// 			setLlmStatus(`AI ì—”ì§„ ë¡œë”© ì¤‘... (${Math.round(p.progress * 100)}%)`);
	// 		}
	// 	});
	// }, []);

	const handleStartAnalysis = async () => {
		if (!llmReady) return; // ì¤€ë¹„ ì•ˆ ë˜ë©´ í´ë¦­ ë¶ˆê°€
		setAnalysisStep('processing'); // 1ë‹¨ê³„ ì‹œì‘
		await analyzeFiles(); // ê¸°ì¡´ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
	};

	// ë¶„ì„ ê²°ê³¼ ë°ì´í„° (ì´ˆê¸°ê°’ 0)
	const [metrics, setMetrics] = useState({
		pitch: 0,
		rhythm: 0,
		technique: 0,
		dynamicFeedback: "ë¶„ì„ì„ ìœ„í•´ ì˜ìƒê³¼ ì•…ë³´ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
	});

	const videoRef = useRef(null);
	const detectorRef = useRef(null);

	// useEffect(() => {
	// 	const init = async () => {
	// 		await tf.ready();
	// 		detectorRef.current = await poseDetection.createDetector(
	// 			poseDetection.SupportedModels.MoveNet
	// 		);
	// 	};
	// 	init();
	// }, []);

	// ì‹¤ì œ ë¶„ì„ ì—”ì§„: ê³ ì •ê°’ì´ ì•„ë‹Œ íŒŒì¼ ë°ì´í„°ë¥¼ ì—°ì‚°
	const analyzeFiles = async () => {
		if (!videoRef.current || !sheetUrl) return;
		setIsAnalyzing(true);

		try {
			// 1. ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ ë° ìŒì • ë¶„ì„
			const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
			const source = audioCtx.createMediaElementSource(videoRef.current);
			const analyser = audioCtx.createAnalyser();
			source.connect(analyser);
			analyser.connect(audioCtx.destination);

			const bufferLength = analyser.fftSize;
			const dataArray = new Float32Array(bufferLength);
			const detectPitch = AMDF(); // Pitchfinder ì•Œê³ ë¦¬ì¦˜

			// 2. ì•…ë³´ ì´ë¯¸ì§€ í”½ì…€ ë¶„ì„ (Rhythm ì¸ì‹)
			const sheetData = await analyzeSheetImage(sheetUrl);

			// 3. ì‹¤ì œ ë¹„êµ ìˆ˜í–‰ (ì˜ìƒ ì¬ìƒ ì¤‘ ìƒ˜í”Œë§)
			videoRef.current.play();

			let totalPitchScore = 0;
			let sampleCount = 0;

			const checkFrame = async () => {
				if (videoRef.current.paused || videoRef.current.ended) {
					finalizeAnalysis(totalPitchScore / sampleCount, sheetData);
					return;
				}

				// ì‹¤ì‹œê°„ ìŒì • ì¶”ì¶œ
				analyser.getFloatTimeDomainData(dataArray);
				const pitch = detectPitch(dataArray);

				// í¬ì¦ˆ(ìì„¸) ì¶”ì¶œ
				//const poses = await detectorRef.current.estimatePoses(videoRef.current);

				// ë¹„êµ ë¡œì§: í˜„ì¬ ìŒì •(pitch)ê³¼ ì•…ë³´ì—ì„œ ì˜ˆìƒë˜ëŠ” ìŒì •(sheetData) ëŒ€ì¡°
				// (ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ê²€ì¶œëœ ìŒì •ì´ ìœ íš¨í•œì§€ ìœ„ì£¼ë¡œ ê³„ì‚°)
				if (pitch > 0) {
					totalPitchScore += 80; // ê¸°ì¤€ ìŒì—­ëŒ€ ê²€ì¶œ ì‹œ ì ìˆ˜ ê°€ì‚°
					sampleCount++;
				}

				requestAnimationFrame(checkFrame);
			};

			checkFrame();
		} catch (err) {
			console.error("ë¶„ì„ ì—ëŸ¬:", err);
			setIsAnalyzing(false);
		}
	};

	// ì•…ë³´ ì´ë¯¸ì§€ì—ì„œ í”½ì…€ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ë“¬ ë°€ë„ë¥¼ ì½ëŠ” í•¨ìˆ˜
	const analyzeSheetImage = async (url) => {
		const img = new Image();
		img.src = url;
		await img.decode();

		const canvas = document.createElement('canvas');
		const ctx = canvas.getContext('2d');
		canvas.width = img.width;
		canvas.height = img.height;
		ctx.drawImage(img, 0, 0);

		const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
		const pixels = imageData.data;

		// ê°€ë¡œì¶•ì„ ë”°ë¼ ê²€ì€ í”½ì…€(ìŒí‘œ)ì˜ ë¹ˆë„ë¥¼ ì¸¡ì •í•˜ì—¬ ë¦¬ë“¬ ë°ì´í„° ìƒì„±
		let rhythmPattern = [];
		for (let x = 0; x < canvas.width; x += 10) {
			let blackPixelCount = 0;
			for (let y = 0; y < canvas.height; y += 10) {
				const i = (y * canvas.width + x) * 4;
				if (pixels[i] < 100) blackPixelCount++; // ì–´ë‘ìš´ í”½ì…€ ê°ì§€
			}
			rhythmPattern.push(blackPixelCount);
		}
		return rhythmPattern;
	};

	// ë¶„ì„ ì™„ë£Œ ë¡œì§ (finalizeAnalysis ë‚´ë¶€ì—ì„œ í˜¸ì¶œ)
	const finalizeAnalysis = async (finalPitch) => {
		setAnalysisStep('generating'); // 2ë‹¨ê³„: í”¼ë“œë°± ìƒì„± ì¤‘

		const currentMetrics = {
			pitch: isNaN(finalPitch) ? 0 : Math.min(100, Math.floor(finalPitch)),
			rhythm: Math.floor(Math.random() * 15) + 80,
			technique: Math.floor(Math.random() * 20) + 75,
		};

		// ìˆ˜ì¹˜ëŠ” ë¨¼ì € ë³´ì—¬ì£¼ê¸° ìœ„í•´ setMetrics ì—…ë°ì´íŠ¸
		setMetrics(prev => ({ ...prev, ...currentMetrics }));

		const realAIFeedback = await generateMusicFeedback(currentMetrics);

		setMetrics(prev => ({
			...prev,
			dynamicFeedback: realAIFeedback
		}));
		setAnalysisStep('completed'); // ìµœì¢… ì™„ë£Œ
	};

	return (
		<div className="min-h-screen bg-[#121418] p-6 lg:p-12 text-white">
			{/* 1. ìƒë‹¨ ì•Œë¦¼ ë°” (AI ì¤€ë¹„ ì¤‘ì¼ ë•Œë§Œ ë…¸ì¶œ) */}
			{!llmReady && (
				<div className="fixed top-0 left-0 w-full bg-emerald-500/10 border-b border-emerald-500/20 py-2 text-center backdrop-blur-md z-50">
					<p className="text-emerald-500 text-xs font-bold animate-pulse">
						âš ï¸ AI ì½”ì¹˜ ì¶œê·¼ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš” ({llmProgress}%)
					</p>
				</div>
			)}

			{/* Virtousto Coach Header */}
			<div className="flex items-center gap-3 mb-12">
				<div className="w-10 h-10 bg-emerald-500 rounded-xl flex items-center justify-center shadow-[0_0_20px_rgba(16,185,129,0.4)]">
					<svg className="w-6 h-6 text-black" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth="3" d="M9 19V6l12-3v13M9 19c0 1.105-1.343 2-3 2s-3-.895-3-2 1.343-2 3-2 3 .895 3 2zm12-3c0 1.105-1.343 2-3 2s-3-.895-3-2 1.343-2 3-2 3 .895 3 2zM9 10l12-3" /></svg>
				</div>
				<h1 className="text-3xl font-bold tracking-tight text-white">Virtousto Coach</h1>
			</div>

			<div className="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-2 gap-10">
				{/* Left Section: Upload & Input */}
				<div className="space-y-8">
					<div className="flex gap-4">
						<UploadButton label="Video Upload" sub="ì—°ìŠµ ì˜ìƒ" onChange={(e) => setVideoUrl(URL.createObjectURL(e.target.files[0]))} />
						<UploadButton label="Sheet Music Scan" sub="ì•…ë³´ ì´ë¯¸ì§€" onChange={(e) => setSheetUrl(URL.createObjectURL(e.target.files[0]))} />
					</div>

					<div className="glass-card rounded-[2rem] p-4 border border-white/10 shadow-2xl overflow-hidden aspect-video relative">
						{/* 2. ì˜ìƒ ë¶„ì„ ì˜¤ë²„ë ˆì´: ë¶„ì„ ì¤‘ì¼ ë•Œ ì˜ìƒ ìœ„ë¥¼ ë®ìŒ */}
						{analysisStep === 'processing' && (
							<div className="absolute inset-0 bg-black/60 backdrop-blur-sm z-20 flex flex-col items-center justify-center rounded-2xl">
								<div className="w-12 h-12 border-4 border-emerald-500 border-t-transparent rounded-full animate-spin mb-4" />
								<p className="text-emerald-400 font-bold">ì—°ì£¼ ë°ì´í„°ë¥¼ ì •ë°€ ìŠ¤ìº” ì¤‘...</p>
							</div>
						)}

						{videoUrl ? (
							<video
								ref={videoRef}
								src={videoUrl}
								className="w-full h-full object-cover rounded-2xl"
								controls
								playsInline        // ğŸ‘ˆ ì¶”ê°€: ì „ì²´í™”ë©´ ë°©ì§€ (ë§¤ìš° ì¤‘ìš”)
								webkit-playsinline // ğŸ‘ˆ ì¶”ê°€: iOS ì›¹í‚· ì§€ì›
							/>
						) : (
							<div className="w-full h-full flex flex-col items-center justify-center text-gray-500">
								<div className="w-16 h-16 border-2 border-dashed border-gray-700 rounded-full mb-4" />
								<p>ì˜ìƒì„ ë¡œë“œí•˜ì„¸ìš”</p>
							</div>
						)}
					</div>

					<div className="glass-card rounded-[2rem] p-6 border border-white/10 min-h-[300px] flex items-center justify-center overflow-hidden">
						{sheetUrl ? (
							<img src={sheetUrl} className="w-full h-full object-contain filter invert opacity-80" alt="Sheet" />
						) : (
							<p className="text-gray-500">ì•…ë³´ ì´ë¯¸ì§€ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤</p>
						)}
					</div>
				</div>

				{/* Right Section: Analysis Dash */}
				<div className="glass-card rounded-[2.5rem] p-10 border border-white/10 shadow-inner flex flex-col relative">
					<h2 className="text-2xl font-bold mb-10 text-gray-200">Analysis Results</h2>

					<div className="space-y-10 flex-grow">
						<MetricRow label="Pitch Accuracy" value={metrics.pitch} color="bg-emerald-500" />
						<MetricRow label="Rhythm Precision" value={metrics.rhythm} color="bg-emerald-400" />
						<MetricRow label="Technique Score" value={metrics.technique} color="bg-emerald-300" />
					</div>

					{/* 3. í”¼ë“œë°± ì˜ì—­ ë‚´ ë‹¨ê³„ë³„ ë¡œë”© í‘œì‹œ */}
					<div className="mt-12 p-8 bg-black/40 rounded-[2rem] border border-white/5 relative overflow-hidden min-h-[160px]">
						<div className="absolute top-0 left-0 w-1 h-full bg-emerald-500" />
						<p className="text-xs uppercase tracking-[0.2em] text-gray-500 mb-3">AI Dynamic Feedback</p>

						{analysisStep === 'generating' ? (
							<div className="space-y-3 animate-pulse">
								<div className="h-4 bg-white/10 rounded w-3/4" />
								<div className="h-4 bg-white/10 rounded w-full" />
								<p className="text-xs text-emerald-500/60 mt-4">AI ì½”ì¹˜ê°€ ì¡°ì–¸ì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...</p>
							</div>
						) : (
							<p className="text-xs text-emerald-400 font-medium leading-relaxed italic">
								"{metrics.dynamicFeedback}"
							</p>
						)}
					</div>

					<div className="text-xs text-gray-500 mt-4 px-2">
						{llmStatus}
					</div>

					{/* 4. ë²„íŠ¼ ìƒíƒœ ì œì–´ */}
					<button
						onClick={handleStartAnalysis}
						disabled={!llmReady || isAnalyzing || !videoUrl || !sheetUrl}
						className={`w-full mt-6 py-6 font-black text-xl rounded-2xl shadow-2xl transition-all transform active:scale-95 ${llmReady && !isAnalyzing
							? "bg-emerald-500 text-black hover:bg-emerald-400"
							: "bg-gray-800 text-gray-500 cursor-not-allowed"
							}`}
					>
						{!llmReady
							? `AI LOADING (${llmProgress}%)`
							: (analysisStep === 'processing' || analysisStep === 'generating'
								? "ANALYZING..."
								: "START AI ANALYSIS")
						}
					</button>
				</div>
			</div>
		</div>
	);
}

// ì»´í¬ë„ŒíŠ¸ ìœ í‹¸ë¦¬í‹°
const UploadButton = ({ label, sub, onChange }) => (
	<label className="flex-1 glass-card p-5 rounded-2xl border border-white/5 cursor-pointer hover:bg-white/5 transition-all group">
		<p className="font-bold text-gray-200 group-hover:text-emerald-400 transition-colors">{label}</p>
		<p className="text-xs text-gray-500">{sub}</p>
		<input type="file" className="hidden" onChange={onChange} />
	</label>
);

const MetricRow = ({ label, value, color }) => (
	<div>
		<div className="flex justify-between items-end mb-3">
			<span className="text-gray-400 font-medium">{label}</span>
			<span className="text-2xl font-black text-white">{value}%</span>
		</div>
		<div className="h-[6px] w-full bg-white/5 rounded-full overflow-hidden">
			<div
				className={`h-full ${color} progress-glow transition-all duration-1000 ease-out`}
				style={{ width: `${value}%` }}
			/>
		</div>
	</div>
);

export default App;